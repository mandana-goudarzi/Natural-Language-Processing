{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IoYYpizuMiwJ"
      },
      "source": [
        "#Lab 1: Introduction to ScikitLearn and Classification Tasks\n",
        "\n",
        "During this Lab, we aim to achieve the following:\n",
        "\n",
        "\n",
        "*   Familiarize with <a href=\"https://scikit-learn.org/stable/\"> scikit-learn </a>, an essential python library in data science;\n",
        "*   learn how to approach a classification task with scikit-learn.\n",
        "\n",
        "In this notebook, we learn to use Scikit-Learn with a practical example and then, in the second part, we will test our knowledge by doing some exercises.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YssOU-ZhNczi"
      },
      "source": [
        "# Part 1: A Classification Example With Scikit-Learn\n",
        "\n",
        "We start our lab by implementing *Logistic Regression* using  scikit-learn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "02sO8JSRMXXZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lhTmIt8NN0ur",
        "outputId": "435213e2-863e-4ad7-dbba-924137c3d048"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ -4.89287606  -2.66252415]\n",
            " [  1.53513244 -17.71701488]\n",
            " [  2.5182605   -1.84224519]\n",
            " [  2.44773955   1.22644053]\n",
            " [  0.26080952 -10.3608732 ]\n",
            " [ -4.93419853 -11.87491308]\n",
            " [-11.14091064  -9.02493302]\n",
            " [ -3.84650002  -3.26967085]\n",
            " [  1.72390928   0.94676316]\n",
            " [  0.22019842  -3.97495822]\n",
            " [ -9.5434103   -9.29414049]\n",
            " [ -8.84586911  -2.47017747]\n",
            " [ -3.15198613  -3.10866018]\n",
            " [  8.04758892  -3.1059307 ]\n",
            " [  4.51512226  -5.69626898]\n",
            " [  1.48372716  -4.72320859]\n",
            " [ -1.24619567  -0.08046855]\n",
            " [ -2.59060124  -7.7649853 ]\n",
            " [  1.97108005   0.72102173]\n",
            " [ -4.10939125 -13.24348766]\n",
            " [  1.15603709  -9.46665443]\n",
            " [  4.52015465   1.10731538]\n",
            " [  0.73655564  -8.96913345]\n",
            " [  5.58087117   0.20618247]\n",
            " [  3.07191791  -2.64967086]\n",
            " [  1.49878533   1.77028153]\n",
            " [  1.76912283  -3.97549865]\n",
            " [ -5.72999469  -3.06430279]\n",
            " [ -1.48573418  -2.71616512]\n",
            " [  0.75656778 -14.52489211]\n",
            " [  0.39325343   4.78726736]\n",
            " [  4.3525562    1.26046682]\n",
            " [  5.17701727  -2.62601201]\n",
            " [ -8.54351608 -12.89055219]\n",
            " [  5.22743541   4.25096275]\n",
            " [ -2.20450457 -17.86340503]\n",
            " [  3.23153752  -4.69734635]\n",
            " [ -1.11186742 -14.00907342]\n",
            " [ -3.95353856   6.01457825]\n",
            " [  4.66399399 -10.84096858]\n",
            " [  9.0491729  -15.44782702]\n",
            " [  0.47555818  -4.30403948]\n",
            " [ -9.15385588   6.1017254 ]\n",
            " [ -3.15122362  -8.06037696]\n",
            " [ -0.90355279  -6.37516939]\n",
            " [ -0.27144665   7.39239411]\n",
            " [ -0.40483213 -17.00885553]\n",
            " [  5.9798991  -11.2189793 ]\n",
            " [  0.26645629  -7.18805983]\n",
            " [ -1.41146055   3.36192515]\n",
            " [ -3.86260476 -14.29130512]\n",
            " [  1.23812248  -6.71483711]\n",
            " [ 12.00286692  -5.54948702]\n",
            " [  2.05994521  -4.42621304]\n",
            " [  3.47270061 -18.97306829]\n",
            " [ -2.04745248  -9.79421096]\n",
            " [ -0.24099163 -13.48603051]\n",
            " [ -3.85055314  -7.42247058]\n",
            " [ -7.02628469 -10.50116054]\n",
            " [ -4.63809988  -9.12624898]\n",
            " [  0.28451234  -7.11398305]\n",
            " [  7.05590431  -7.49455213]\n",
            " [ -3.30528171  -1.73304528]\n",
            " [ -2.54981015  -6.35887782]\n",
            " [ -3.66831237  -3.02096815]\n",
            " [ -2.3986289  -11.57485513]\n",
            " [  2.4717163    1.84148009]\n",
            " [ -4.02468805 -15.31120342]\n",
            " [  3.93093026  -2.74942371]\n",
            " [  1.12513971  -7.93782106]\n",
            " [ -2.59655295 -11.75042511]\n",
            " [ -0.84637325   0.78964926]\n",
            " [ -0.48289076  -4.84126903]\n",
            " [ -2.44923223  -4.74553642]\n",
            " [  0.29231134  -2.89470507]\n",
            " [ -2.80156312  -9.78308195]\n",
            " [  5.1573984   -4.21716504]\n",
            " [ -0.45305964  -3.78435558]\n",
            " [  6.40229254  -0.06790334]\n",
            " [  4.88441643   1.77784776]\n",
            " [  8.82253527  -5.63027727]\n",
            " [ -4.34289788  -9.49720619]\n",
            " [ -6.50088654   0.04492451]\n",
            " [  2.35367856   6.41917028]\n",
            " [  1.1958282   -9.28719447]\n",
            " [  0.66015579  -2.52745182]\n",
            " [ -8.62308131  -1.05654641]\n",
            " [ -3.32837229  -3.93792329]\n",
            " [ -0.28530794  -6.76106066]\n",
            " [ -5.86929172  -7.72745052]\n",
            " [ -4.83643892 -10.11503375]\n",
            " [  1.22511589  -0.64924378]\n",
            " [ -1.32084595  -0.10920227]\n",
            " [  3.46433311   0.4216103 ]\n",
            " [  1.95657702  -4.36789003]\n",
            " [  0.84329858  -6.50359308]\n",
            " [ -7.28408714  -6.0539122 ]\n",
            " [ 17.63345468   2.03198741]\n",
            " [  0.98431345  -1.85768427]\n",
            " [ -1.28006242  -7.28494745]\n",
            " [ -2.97833371 -10.0174074 ]\n",
            " [ -2.82524371  -9.21219488]\n",
            " [  5.39076549   2.3602744 ]\n",
            " [ -4.09123068   2.50601072]\n",
            " [  0.75241973 -12.90054086]\n",
            " [  7.19687884  -9.33622753]\n",
            " [  2.77137988 -11.02490006]\n",
            " [ -1.74350821 -11.49908085]\n",
            " [ -2.65233092 -10.43802069]\n",
            " [ -5.69816162  -4.02998239]\n",
            " [  0.95328692  -0.19803291]\n",
            " [  1.33897551   1.40105168]\n",
            " [  3.21192833 -16.62939216]\n",
            " [ -5.56480844 -13.1629562 ]\n",
            " [ -8.31883795  -5.26613835]\n",
            " [ -2.36978265  -0.44443987]\n",
            " [-12.05087226  -9.85185849]\n",
            " [ -1.35758047  -4.72272042]\n",
            " [  1.76535568 -13.50620735]\n",
            " [  2.5991562   -2.56775276]\n",
            " [ -2.91586565 -15.08877596]\n",
            " [  4.25720151  -4.54903855]\n",
            " [ -2.02229108  -5.35106371]\n",
            " [ -3.6007403   -4.15860674]\n",
            " [  1.53949986  -6.65693946]\n",
            " [ -2.51165203   0.98896885]\n",
            " [ -4.19308001 -11.84430447]\n",
            " [ -5.94872346  -1.60394238]\n",
            " [  2.57395018   2.65726097]\n",
            " [  3.42406008  -7.91785927]\n",
            " [ -3.92576554  -6.06952742]\n",
            " [  5.52069083  -2.40423261]\n",
            " [ -7.2013744   -0.20826321]\n",
            " [ -3.45890454  -4.05375126]\n",
            " [ -1.44036143  -8.16116146]\n",
            " [ -3.69138208   3.70428831]\n",
            " [ -0.95069014  -5.423131  ]\n",
            " [  0.34636683   0.92968142]\n",
            " [ -4.3089793   -9.4449231 ]\n",
            " [ -1.51117116   0.24056544]\n",
            " [ -7.54413413 -17.9162157 ]\n",
            " [  0.96246495  -5.07556633]\n",
            " [ -5.57633805  -7.08522595]\n",
            " [ -7.03603173 -10.10313091]\n",
            " [  6.15299557  -7.69668138]\n",
            " [  0.90308424 -11.89592215]\n",
            " [ -1.83434298  -0.32174979]\n",
            " [ -5.41683162  -7.73027277]\n",
            " [  3.68334628   1.68273076]\n",
            " [ -0.15500448   0.88706612]]\n",
            "[1 0 1 1 0 0 0 1 1 0 0 0 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 0 1 0 1 1 1 0 1 0 1\n",
            " 0 1 0 0 0 1 0 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 1 0 1 0 1 0 1 1 0 1 1 1\n",
            " 1 0 1 0 1 1 1 1 1 1 0 1 1 1 1 0 0 1 1 1 0 0 0 1 1 0 0 0 1 1 0 1 0 0 0 1 0\n",
            " 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 1 0 0 1 1 1 0 1 1 1 0 1 0 1 0 0 0 0 1 0\n",
            " 1 1]\n",
            "Counter({1: 75, 0: 75})\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x800 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "X_toy, y_toy = datasets.make_blobs(n_samples=150,n_features=2,\n",
        "                           centers=2,cluster_std=4.05,\n",
        "                           random_state=2) # create an artificial dataset\n",
        "print(X_toy)\n",
        "print(y_toy)\n",
        "\n",
        "print(Counter(y_toy))\n",
        "\n",
        "#Plotting the data\n",
        "fig = plt.figure(figsize=(10,8))\n",
        "plt.plot(X_toy[:, 0][y_toy == 0], X_toy[:, 1][y_toy == 0], 'r^')\n",
        "plt.plot(X_toy[:, 0][y_toy == 1], X_toy[:, 1][y_toy == 1], 'bs')\n",
        "plt.xlabel(\"X1\")\n",
        "plt.ylabel(\"X2\")\n",
        "plt.title('Random Classification Data with 2 classes')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0q2QIo9EPe7h"
      },
      "source": [
        "We can now define our classifier: logistic regression <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\"> [link] </a>."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "RYjwdbMaPvsX"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "clf_lr = LogisticRegression() # options for the classifiers are passed as parameters to constructor of the class\n",
        "                              # LogisticRegression(). Either visit the link or put the cursor over it to see them\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-N6MC_b2QJ_K"
      },
      "source": [
        "Sklearn defines standard functions for models, like *fit* and *predict*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4qlKvhrQQnV",
        "outputId": "1715b435-f21f-49d6-c1b5-5e8bb2a37d2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1 0 1 1 0 0 0 1 1 1 0 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 1 0 1 1 1 0 1 0 1\n",
            " 0 1 0 0 1 1 0 0 1 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 1 1 1\n",
            " 1 0 1 1 1 1 1 0 1 1 0 1 1 1 0 0 0 1 1 1 1 0 0 1 1 0 0 0 1 1 0 0 0 0 0 0 1\n",
            " 1 0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 1 0 0 1 1 1 0 1 0 1 0 1 0 1 0 0 0 0 1 0\n",
            " 1 1]\n"
          ]
        }
      ],
      "source": [
        "#train phase\n",
        "clf_lr.fit(X_toy, y_toy)\n",
        "\n",
        "\n",
        "#estimation (y_hat)\n",
        "y_pred_cl_lr = clf_lr.predict(X_toy)\n",
        "\n",
        "print(y_pred_cl_lr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7v6JjDVQnLH"
      },
      "source": [
        "How to evaluate our models' performance? <br>\n",
        "Scikit-learn offers a broad set of evaluation functions already implemented <a href = \"https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics\">[link]</a>."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3wse3MyQmp7",
        "outputId": "e9aa77d6-d695-4ab8-f7a9-f926ca59cc08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression -- Toy dataset.\tACC: 0.8466666666666667\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print(f\"Logistic Regression -- Toy dataset.\\tACC: {accuracy_score(y_toy, y_pred_cl_lr)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IE_Ct3EkHOOT",
        "outputId": "3ce9cecb-64af-41bd-b266-1ffdfffad129"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.13964848 0.50949748]\n"
          ]
        }
      ],
      "source": [
        "# printing the values of the parameters after learning\n",
        "\n",
        "print(clf_lr.coef_[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpjsDkvVN_vD"
      },
      "source": [
        "## Model Selection\n",
        "When defining or training a model, we have the so called *hyperparameters*, i.e., different settings to configure for our training strategy.  <br>\n",
        "The question is: *how can we decide the best configuration setting for the task?* <br>\n",
        "The answer is the usage of *training* and *validation* partitions. <br>\n",
        "We can use sklearn to do that: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u53o2430OsJG",
        "outputId": "2da18978-4103-47b7-fed1-3447f44d5cf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original size = 150\tTrain size = 120\tVal size = 30\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_toy, y_toy,\n",
        "                                                  train_size = 0.8, shuffle=False, random_state=42)\n",
        "\n",
        "print(f\"Original size = {X_toy.shape[0]}\\tTrain size = {X_train.shape[0]}\\tVal size = {X_val.shape[0]}\")  # alternative way to use the print when there are\n",
        "                                                                                                          # variables and text to print together\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfmw2jjz4g_M"
      },
      "source": [
        "First we use Scikit-Learn to train a <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\">Logistic Regression</a> classifier with default parameters over the Toy dataset. <br>\n",
        "We compute the accuracy on both training and validation sets.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4avSSrcSFK0",
        "outputId": "045314af-0931-4671-bc6e-a6d79f6c15c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression.\tTrain ACC: 0.8416666666666667\n",
            "Logistic Regression.\tVal ACC: 0.8666666666666667\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "clf_lr = LogisticRegression()\n",
        "clf_lr.fit(X_train, y_train)\n",
        "\n",
        "#estimation (y_hat)\n",
        "y_train_pred_lr = clf_lr.predict(X_train)\n",
        "y_val_pred_lr = clf_lr.predict(X_val)\n",
        "\n",
        "print(f\"Logistic Regression.\\tTrain ACC: {accuracy_score(y_train, y_train_pred_lr)}\")\n",
        "print(f\"Logistic Regression.\\tVal ACC: {accuracy_score(y_val, y_val_pred_lr)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bx_dh_GgLcgG"
      },
      "source": [
        "### Model Selection with Logistic Regression\n",
        "\n",
        "Logistic Regression has a hyperparameter *C*. Lower values of C correspond to simpler models (with the risk of underfitting), higher values of C correspond to complex models (with the risk of overfitting).  \n",
        "Let's see how the performance change by varying it.\n",
        "\n",
        "Let's find the best *C* among the following: $C = [0.001, 0.01, 0.1, 1., 10]$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOGc2ZMhLcgI",
        "outputId": "ad1bdf9d-ba6e-4691-f861-d4410471c021"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LR. C= 0.001.\tTrain ACC: 0.8416666666666667\tVal Acc: 0.9\n",
            "LR. C= 0.01.\tTrain ACC: 0.8416666666666667\tVal Acc: 0.9\n",
            "LR. C= 0.1.\tTrain ACC: 0.8416666666666667\tVal Acc: 0.8666666666666667\n",
            "LR. C= 1.0.\tTrain ACC: 0.8416666666666667\tVal Acc: 0.8666666666666667\n",
            "LR. C= 10.\tTrain ACC: 0.8416666666666667\tVal Acc: 0.8666666666666667\n",
            "LR. C= 100.\tTrain ACC: 0.8416666666666667\tVal Acc: 0.8666666666666667\n"
          ]
        }
      ],
      "source": [
        "C = [0.001, 0.01, 0.1, 1., 10, 100]\n",
        "for c in C:\n",
        "    clf_lr = LogisticRegression(C = c)\n",
        "    clf_lr.fit(X_train, y_train)\n",
        "\n",
        "    #estimation (y_hat)\n",
        "    y_train_pred_lr = clf_lr.predict(X_train)\n",
        "    y_val_pred_lr = clf_lr.predict(X_val)\n",
        "    tr_acc = accuracy_score(y_train, y_train_pred_lr)\n",
        "    val_acc= accuracy_score(y_val, y_val_pred_lr)\n",
        "\n",
        "    print(f\"LR. C= {c}.\\tTrain ACC: {tr_acc}\\tVal Acc: {val_acc}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uc3M8SxBLkjL"
      },
      "source": [
        "### Exercise: Model Selection with Logistic Regression\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwnRlnJITqat"
      },
      "source": [
        "We ask you again to work on a classification task. <br>\n",
        "This time, the classification is more challenging.\n",
        "The dataset is called *sonar*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "RPaGZnJTTzYH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(208, 60) (208,)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "random.seed(42)\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/sonar.csv'\n",
        "ds = pd.read_csv(url, header = None)\n",
        "\n",
        "# split into input and output elements\n",
        "data = ds.values\n",
        "random.shuffle(data)\n",
        "X_sonar, y_sonar = data[:, :-1], data[:, -1]\n",
        "\n",
        "print(X_sonar.shape, y_sonar.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_8KkpEiVDH2"
      },
      "source": [
        "It's time to partition our dataset. <br>\n",
        "We ask you to create three partitions:\n",
        "\n",
        "\n",
        "*   *train set* : a set of samples used to train a model.\n",
        "*   *val set*: a set of samples used to decide the best model.\n",
        "*   *test set*: a set of samples used to see our best model performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3Cl4DNbISPc"
      },
      "source": [
        "We now first split samples that we can use in our training (train and val), from samples that we cannot touch (test). <br>\n",
        "**EX 1** Create a split between train_val and test, by maintaining the 25% of samples in the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "piMMVXyBVPXy"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original size: 208\tTrain Validation size: 156\tTest size: 52\n"
          ]
        }
      ],
      "source": [
        "#\n",
        "# Ex 1: complete here\n",
        "X_train_val, X_test, y_train_val, y_test= train_test_split(X_sonar, y_sonar, train_size=0.75, shuffle=False, random_state=42)\n",
        "print(f\"Original size: {X_sonar.shape[0]}\\tTrain Validation size: {X_train_val.shape[0]}\\tTest size: {X_test.shape[0]}\")\n",
        "#\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puQHU1EiI5lW"
      },
      "source": [
        "**EX 1.2** From the train_val variables, split train and validation sets. Maintain the 10% of samples in the validation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "PK3dVG5VJJcW"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train size: 140\tTest size: 16\n"
          ]
        }
      ],
      "source": [
        "#\n",
        "# Ex 1.2: complete here\n",
        "X_train, X_val, y_train, y_val=train_test_split(X_train_val, y_train_val, train_size=0.9, shuffle=False, random_state=42)\n",
        "print(f\"Train size: {X_train.shape[0]}\\tTest size: {X_val.shape[0]}\")\n",
        "#\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "wj6e3dg3MyM6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(140, 60) (16, 60) (52, 60)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape, X_val.shape, X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHh4F6EonDL4"
      },
      "source": [
        "**EX 2** Train and evaluate (using accuracy) a logistic regression with the default value for the hyperparameter. Do the evaluation **only** on the training and validation partitions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "8pVIcHmWVphu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Resgression.\tTrain ACC: 0.9428571428571428\n",
            "Logistic Regression.\tValidation ACC: 0.8125\n"
          ]
        }
      ],
      "source": [
        "#\n",
        "# Ex 2: complete here\n",
        "lr = LogisticRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "y_train_pre_lr = lr.predict(X_train)\n",
        "y_val_pre_lr = lr.predict(X_val)\n",
        "\n",
        "print(f\"Logistic Resgression.\\tTrain ACC: {accuracy_score(y_train, y_train_pre_lr)}\")\n",
        "print(f\"Logistic Regression.\\tValidation ACC: {accuracy_score(y_val, y_val_pre_lr)}\")\n",
        "#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRwSJs1gVsPk"
      },
      "source": [
        "Let's find the best value for *C*, an hyperparameter of the model. <br>\n",
        "See the documentation <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\"> [link] </a>. <br>\n",
        "**EX 3**  We ask you to find the best *C* among the following: $C = [0.001, 0.01, 0.1, 1., 10, 100, 1000, 10000]$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "mloaRMsPWg0I"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression. C=0.001\tTrain ACC: 0.9428571428571428\tValidation ACC: 0.8125\n",
            "Logistic Regression. C=0.01\tTrain ACC: 0.9428571428571428\tValidation ACC: 0.8125\n",
            "Logistic Regression. C=0.1\tTrain ACC: 0.9428571428571428\tValidation ACC: 0.8125\n",
            "Logistic Regression. C=1.0\tTrain ACC: 0.9428571428571428\tValidation ACC: 0.8125\n",
            "Logistic Regression. C=10\tTrain ACC: 0.9571428571428572\tValidation ACC: 0.8125\n",
            "Logistic Regression. C=100\tTrain ACC: 0.9928571428571429\tValidation ACC: 0.875\n",
            "Logistic Regression. C=1000\tTrain ACC: 1.0\tValidation ACC: 0.9375\n",
            "Logistic Regression. C=10000\tTrain ACC: 1.0\tValidation ACC: 0.9375\n"
          ]
        }
      ],
      "source": [
        "#\n",
        "# Ex 3: complete here\n",
        "#\n",
        "C = [0.001, 0.01, 0.1, 1., 10, 100, 1000, 10000]\n",
        "for c in C:\n",
        "    lr = LogisticRegression(C=c, max_iter=1000)\n",
        "    lr.fit(X_train, y_train)\n",
        "    y_train_pre_lr = lr.predict(X_train)\n",
        "    y_val_pre_lr = lr.predict(X_val)\n",
        "    tr_acc = accuracy_score(y_train, y_train_pre_lr)\n",
        "    val_acc= accuracy_score(y_val, y_val_pre_lr)\n",
        "    print(f\"Logistic Regression. C={c}\\tTrain ACC: {tr_acc}\\tValidation ACC: {val_acc}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unODdeVJUren"
      },
      "source": [
        "**Ex 4** It's time to see the performance on the test set of the best model, after training it on the training set. Use the accuracy as evaluation metric."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "j912RT_fUren"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression. C=100\tTest ACC: 0.7115384615384616\n"
          ]
        }
      ],
      "source": [
        "#\n",
        "# Ex 4: complete here\n",
        "#\n",
        "lr = LogisticRegression(C= 100, max_iter= 1000)\n",
        "lr.fit(X_train, y_train)\n",
        "y_test_pre_lr = lr.predict(X_test)\n",
        "test_acc = accuracy_score(y_test, y_test_pre_lr)\n",
        "print(f\"Logistic Regression. C=100\\tTest ACC: {test_acc}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzBzTV8-nqJp"
      },
      "source": [
        "## Computing Vectorial Representations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting spacy\n",
            "  Downloading spacy-3.8.4-cp311-cp311-macosx_11_0_arm64.whl.metadata (27 kB)\n",
            "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
            "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
            "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
            "  Downloading murmurhash-1.0.12-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
            "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
            "  Downloading cymem-2.0.11-cp311-cp311-macosx_11_0_arm64.whl.metadata (8.5 kB)\n",
            "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
            "  Downloading preshed-3.0.9-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.2 kB)\n",
            "Collecting thinc<8.4.0,>=8.3.4 (from spacy)\n",
            "  Downloading thinc-8.3.4-cp311-cp311-macosx_11_0_arm64.whl.metadata (15 kB)\n",
            "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
            "  Downloading wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
            "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
            "  Downloading srsly-2.5.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (19 kB)\n",
            "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
            "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting weasel<0.5.0,>=0.1.0 (from spacy)\n",
            "  Downloading weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting typer<1.0.0,>=0.3.0 (from spacy)\n",
            "  Downloading typer-0.15.2-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/goudarzimandanagmail.com/anaconda3/lib/python3.11/site-packages (from spacy) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /Users/goudarzimandanagmail.com/anaconda3/lib/python3.11/site-packages (from spacy) (1.24.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/goudarzimandanagmail.com/anaconda3/lib/python3.11/site-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/goudarzimandanagmail.com/anaconda3/lib/python3.11/site-packages (from spacy) (1.10.8)\n",
            "Requirement already satisfied: jinja2 in /Users/goudarzimandanagmail.com/anaconda3/lib/python3.11/site-packages (from spacy) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /Users/goudarzimandanagmail.com/anaconda3/lib/python3.11/site-packages (from spacy) (68.0.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/goudarzimandanagmail.com/anaconda3/lib/python3.11/site-packages (from spacy) (23.1)\n",
            "Collecting langcodes<4.0.0,>=3.2.0 (from spacy)\n",
            "  Downloading langcodes-3.5.0-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy)\n",
            "  Downloading language_data-1.3.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/goudarzimandanagmail.com/anaconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/goudarzimandanagmail.com/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/goudarzimandanagmail.com/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/goudarzimandanagmail.com/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/goudarzimandanagmail.com/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.2.2)\n",
            "Collecting blis<1.3.0,>=1.2.0 (from thinc<8.4.0,>=8.3.4->spacy)\n",
            "  Downloading blis-1.2.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (7.7 kB)\n",
            "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.4->spacy)\n",
            "  Downloading confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: click>=8.0.0 in /Users/goudarzimandanagmail.com/anaconda3/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.0.4)\n",
            "Collecting shellingham>=1.3.0 (from typer<1.0.0,>=0.3.0->spacy)\n",
            "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: rich>=10.11.0 in /Users/goudarzimandanagmail.com/anaconda3/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.7.1)\n",
            "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.1.0->spacy)\n",
            "  Downloading cloudpathlib-0.21.0-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /Users/goudarzimandanagmail.com/anaconda3/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (5.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/goudarzimandanagmail.com/anaconda3/lib/python3.11/site-packages (from jinja2->spacy) (2.1.1)\n",
            "Collecting marisa-trie>=1.1.0 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy)\n",
            "  Downloading marisa_trie-1.2.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/goudarzimandanagmail.com/anaconda3/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/goudarzimandanagmail.com/anaconda3/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.15.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /Users/goudarzimandanagmail.com/anaconda3/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.0)\n",
            "Downloading spacy-3.8.4-cp311-cp311-macosx_11_0_arm64.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
            "Downloading cymem-2.0.11-cp311-cp311-macosx_11_0_arm64.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langcodes-3.5.0-py3-none-any.whl (182 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.0/183.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading murmurhash-1.0.12-cp311-cp311-macosx_11_0_arm64.whl (26 kB)\n",
            "Downloading preshed-3.0.9-cp311-cp311-macosx_11_0_arm64.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.8/128.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
            "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
            "Downloading srsly-2.5.1-cp311-cp311-macosx_11_0_arm64.whl (634 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m634.4/634.4 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading thinc-8.3.4-cp311-cp311-macosx_11_0_arm64.whl (774 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m774.2/774.2 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading typer-0.15.2-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.1/45.1 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
            "Downloading weasel-0.4.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.3/50.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading blis-1.2.0-cp311-cp311-macosx_11_0_arm64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading cloudpathlib-0.21.0-py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading confection-0.1.5-py3-none-any.whl (35 kB)\n",
            "Downloading language_data-1.3.0-py3-none-any.whl (5.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
            "\u001b[?25hDownloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Downloading marisa_trie-1.2.1-cp311-cp311-macosx_11_0_arm64.whl (174 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.0/175.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: cymem, wasabi, spacy-loggers, spacy-legacy, shellingham, murmurhash, marisa-trie, cloudpathlib, catalogue, blis, srsly, preshed, language-data, typer, langcodes, confection, weasel, thinc, spacy\n",
            "Successfully installed blis-1.2.0 catalogue-2.0.10 cloudpathlib-0.21.0 confection-0.1.5 cymem-2.0.11 langcodes-3.5.0 language-data-1.3.0 marisa-trie-1.2.1 murmurhash-1.0.12 preshed-3.0.9 shellingham-1.5.4 spacy-3.8.4 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.5.1 thinc-8.3.4 typer-0.15.2 wasabi-1.1.3 weasel-0.4.1\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install spacy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: en-core-web-sm\n",
            "Successfully installed en-core-web-sm-3.8.0\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download en_core_web_sm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VZ9ywJrtGAb",
        "outputId": "a62c3624-454e-45d5-9997-708a664b8297"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25h\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download \"en_core_web_sm\"\n",
        "import spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhPtwraBfYrc",
        "outputId": "3b7694eb-4f25-4ee3-81eb-ff9570e1d56a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['and' 'document' 'first' 'forth' 'is' 'one' 'or' 'second' 'the' 'third'\n",
            " 'this']\n",
            "vocabulary size: 11\n",
            "['.' '?' 'and' 'document' 'first' 'forth' 'is' 'one' 'or' 'second' 'the'\n",
            " 'third' 'this']\n",
            "vocabulary size: 13\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/goudarzimandanagmail.com/anaconda3/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "corpus = [\n",
        "    'This is the first document.',\n",
        "    'This document is the second document.',\n",
        "    'And this is the third one.',\n",
        "    'Is this the first document or the forth?',\n",
        "]\n",
        "Y = [1, 0, 0, 1]\n",
        "\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(corpus)            # extracts the vocabulary from corpus (the list of unique words in corpus)\n",
        "X = vectorizer.transform(corpus)  # build the bag of words representation of corpus with respect to the vocabulary computed with fit on the previous row\n",
        "\n",
        "print(vectorizer.get_feature_names_out())\n",
        "print(\"vocabulary size:\", len(vectorizer.get_feature_names_out()))\n",
        "\n",
        "# Let's see some of the options of CountVectorizer (first we change the tokenizer)\n",
        "nlp_en = spacy.load(\"en_core_web_sm\", disable=['ner', 'parser'])\n",
        "\n",
        "def spacy_tokenizer(text):\n",
        "  return [token.text for token in nlp_en(text)]\n",
        "\n",
        "vectorizer2 = CountVectorizer(binary=False, tokenizer=spacy_tokenizer)\n",
        "X=vectorizer2.fit_transform(corpus)\n",
        "\n",
        "print(vectorizer2.get_feature_names_out())\n",
        "print(\"vocabulary size:\", len(vectorizer2.get_feature_names_out()))\n",
        "\n",
        "# now we can use X and Y in a learning algorithm\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxwU3b4jNe88"
      },
      "source": [
        "#Sentiment Analysis\n",
        "\n",
        "The dataset is described here: https://www.aclweb.org/anthology/P04-1035.pdf\n",
        "\n",
        "It is part of nltk, so it is convenient for us to use.\n",
        "\n",
        "The goal of this exercise is to build a first machine learning model using the tools that we have seen so far: choose how to preprocess the text, create a bag of words feature representation, train a model using an ML method of your choice.\n",
        "\n",
        "You need to use the following split for the data:\n",
        "\n",
        "*   test: 30% of the documents\n",
        "*   The rest of the documents will be split as\n",
        "    *   train: 75% of the documents\n",
        "    *   validation: 25% of the documents\n",
        "\n",
        "After splitting the data, turn the reviews into vectors, then apply a ML algorithm. Use accuracy as evaluation measure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVI9mm47Du9z",
        "outputId": "358e84a4-6cbe-4184-c857-f5ed43c4e650"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package movie_reviews to\n",
            "[nltk_data]     /Users/goudarzimandanagmail.com/nltk_data...\n",
            "[nltk_data]   Package movie_reviews is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/goudarzimandanagmail.com/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('movie_reviews') # loads the dataset\n",
        "nltk.download('punkt')\n",
        "#!python -m spacy download \"en_core_web_sm\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zplVPbgmclWr"
      },
      "source": [
        "## Loading the data\n",
        "In the following I extract the raw content of the reviews (movie_reviews.raw()), i.e. each review is a string.\n",
        "Another option is to use movie_reviews.words() that returns each review as a list of tokens. Feel free to use whichever best fit your needs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "-y8LNMr-JdeJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of docs loaded: 2000\n",
            "plot : two teen couples go to a church party , drink and then drive . \n",
            "they get into an accident . \n",
            "one of the guys dies , but his girlfriend continues to see him in her life , and has nightmares . \n",
            "what's the deal ? \n",
            "watch the movie and \" sorta \" find out . . . \n",
            "critique : a mind-fuck movie for the teen generation that touches on a very cool idea , but presents it in a very bad package . \n",
            "which is what makes this review an even harder one to write , since i generally applaud films which attempt to break the mold , mess with your head and such ( lost highway & memento ) , but there are good and bad ways of making all types of films , and these folks just didn't snag this one correctly . \n",
            "they seem to have taken this pretty neat concept , but executed it terribly . \n",
            "so what are the problems with the movie ? \n",
            "well , its main problem is that it's simply too jumbled . \n",
            "it starts off \" normal \" but then downshifts into this \" fantasy \" world in which you , as an audience member , have no idea what's going on . \n",
            "there are dreams , there are characters coming back from the dead , there are others who look like the dead , there are strange apparitions , there are disappearances , there are a looooot of chase scenes , there are tons of weird things that happen , and most of it is simply not explained . \n",
            "now i personally don't mind trying to unravel a film every now and then , but when all it does is give me the same clue over and over again , i get kind of fed up after a while , which is this film's biggest problem . \n",
            "it's obviously got this big secret to hide , but it seems to want to hide it completely until its final five minutes . \n",
            "and do they make things entertaining , thrilling or even engaging , in the meantime ? \n",
            "not really . \n",
            "the sad part is that the arrow and i both dig on flicks like this , so we actually figured most of it out by the half-way point , so all of the strangeness after that did start to make a little bit of sense , but it still didn't the make the film all that more entertaining . \n",
            "i guess the bottom line with movies like this is that you should always make sure that the audience is \" into it \" even before they are given the secret password to enter your world of understanding . \n",
            "i mean , showing melissa sagemiller running away from visions for about 20 minutes throughout the movie is just plain lazy ! ! \n",
            "okay , we get it . . . there \n",
            "are people chasing her and we don't know who they are . \n",
            "do we really need to see it over and over again ? \n",
            "how about giving us different scenes offering further insight into all of the strangeness going down in the movie ? \n",
            "apparently , the studio took this film away from its director and chopped it up themselves , and it shows . \n",
            "there might've been a pretty decent teen mind-fuck movie in here somewhere , but i guess \" the suits \" decided that turning it into a music video with little edge , would make more sense . \n",
            "the actors are pretty good for the most part , although wes bentley just seemed to be playing the exact same character that he did in american beauty , only in a new neighborhood . \n",
            "but my biggest kudos go out to sagemiller , who holds her own throughout the entire film , and actually has you feeling her character's unraveling . \n",
            "overall , the film doesn't stick because it doesn't entertain , it's confusing , it rarely excites and it feels pretty redundant for most of its runtime , despite a pretty cool ending and explanation to all of the craziness that came before it . \n",
            "oh , and by the way , this is not a horror or teen slasher flick . . . it's \n",
            "just packaged to look that way because someone is apparently assuming that the genre is still hot with the kids . \n",
            "it also wrapped production two years ago and has been sitting on the shelves ever since . \n",
            "whatever . . . skip \n",
            "it ! \n",
            "where's joblo coming from ? \n",
            "a nightmare of elm street 3 ( 7/10 ) - blair witch 2 ( 7/10 ) - the crow ( 9/10 ) - the crow : salvation ( 4/10 ) - lost highway ( 10/10 ) - memento ( 10/10 ) - the others ( 9/10 ) - stir of echoes ( 8/10 ) \n",
            "\n",
            "neg\n"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import movie_reviews\n",
        "import random\n",
        "import spacy\n",
        "from scipy.sparse import coo_matrix, vstack\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "nlp_en = spacy.load(\"en_core_web_sm\", disable=['ner', 'parser'])\n",
        "\n",
        "documents = [(movie_reviews.raw(fileid), category)\n",
        "              for category in movie_reviews.categories()\n",
        "              for fileid in movie_reviews.fileids(category)]\n",
        "\n",
        "print(\"number of docs loaded:\", len(documents))\n",
        "\n",
        "corpus_raw = [ x[0] for x in documents ]  # corpus_raw is a list of strings (reviews) to be converted into vectors\n",
        "y_corpus = [ x[1] for x in documents ]    # y_corpus are the sentiment labels of the reviews (nothing to be done here)\n",
        "print(corpus_raw[0])\n",
        "print(y_corpus[0])\n",
        "\n",
        "random.seed(42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2000,)\n",
            "(2000,)\n"
          ]
        }
      ],
      "source": [
        "print(np.shape(corpus_raw))\n",
        "print(np.shape(y_corpus))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMBhcMfLuxrl"
      },
      "source": [
        "## Exercise - Lab. 1 Assignment\n",
        "\n",
        "Create a vectorial representation of the data, then apply a learning algorithm by optimising the hyperparameters on the validation set. If you need to use any function that depends on random number generators, use 42 as seed.\n",
        "Test several representations. You may try functions of the libraries we have seen in class or make your own vectorial representation from scratch.\n",
        "Once you have selected the best hyperparameters and preprocessing, retrain your model on the union of the training and validation sets, then compute the accuracy on the test set.\n",
        "\n",
        "Report your test performance on Moodle. In Moodle you are also supposed to upload the notebook in .py format (Menu File->Download->Download .py)\n",
        "In the file with your code motivate any significant choice you made and all different preprocessing you attempted (clearly highlight the best one, though).\n",
        "\n",
        "**Bonus Exercise** for your best model, print the 30 tokens whose corresponding parameter have highest absolute value. What do you think of this list? Does it make sense? Are all tokens expected?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['00' '000' '0009f' ... 'zwigoff' 'zycie' 'zzzzzzz']\n",
            "39659\n"
          ]
        }
      ],
      "source": [
        "vectorizer = CountVectorizer()\n",
        "vectorizer.fit(corpus_raw)\n",
        "X1 = vectorizer.transform(corpus_raw)\n",
        "print(vectorizer.get_feature_names_out())\n",
        "print(len(vectorizer.get_feature_names_out()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2000, 39659)"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['\\x05' '\\n' '\\n ' ... '|' '||' '}']\n",
            "40111\n"
          ]
        }
      ],
      "source": [
        "nlp_en = spacy.load(\"en_core_web_sm\", disable=['ner', 'parser'])\n",
        "\n",
        "def spacy_tokenizer(text):\n",
        "    return [token.text for token in nlp_en(text)]\n",
        "vectorizer2 = CountVectorizer(binary=False, tokenizer=spacy_tokenizer)\n",
        "X2 = vectorizer2.fit_transform(corpus_raw)\n",
        "print(vectorizer2.get_feature_names_out())\n",
        "print(len(vectorizer2.get_feature_names_out()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of features: 494307\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer(tokenizer=spacy_tokenizer, ngram_range=(1, 2))\n",
        "X3 = vectorizer.fit_transform(corpus_raw)\n",
        "print(\"Number of features:\", len(vectorizer.get_feature_names_out()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original size: 2000\tTrain Validation set: 1500\tTest set: 500\n"
          ]
        }
      ],
      "source": [
        "X_train_val, X_test, y_train_val, y_test = train_test_split(X3, y_corpus, train_size=0.75, shuffle=True, random_state=42)\n",
        "print(f\"Original size: {X3.shape[0]}\\tTrain Validation set: {X_train_val.shape[0]}\\tTest set: {X_test.shape[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train size: 1350\tValidation size: 150\n"
          ]
        }
      ],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, train_size=0.9, shuffle=True, random_state=42)\n",
        "print(f\"Train size: {X_train.shape[0]}\\tValidation size: {X_val.shape[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LR. C = 0.001\ttrain acc: 0.5037037037037037\tvalidation acc: 0.5133333333333333\n",
            "LR. C = 0.01\ttrain acc: 0.5703703703703704\tvalidation acc: 0.52\n",
            "LR. C = 0.02\ttrain acc: 0.7674074074074074\tvalidation acc: 0.64\n",
            "LR. C = 0.03\ttrain acc: 0.8392592592592593\tvalidation acc: 0.68\n",
            "LR. C = 0.035\ttrain acc: 0.8577777777777778\tvalidation acc: 0.6933333333333334\n",
            "LR. C = 0.04\ttrain acc: 0.8718518518518519\tvalidation acc: 0.6866666666666666\n",
            "LR. C = 0.05\ttrain acc: 0.8918518518518519\tvalidation acc: 0.7133333333333334\n",
            "LR. C = 0.08\ttrain acc: 0.9044444444444445\tvalidation acc: 0.7\n",
            "LR. C = 0.09\ttrain acc: 0.9118518518518518\tvalidation acc: 0.7066666666666667\n",
            "LR. C = 10\ttrain acc: 0.9992592592592593\tvalidation acc: 0.7933333333333333\n",
            "LR. C = 15\ttrain acc: 1.0\tvalidation acc: 0.7933333333333333\n"
          ]
        }
      ],
      "source": [
        "C = [0.001, 0.01, 0.02, 0.03, 0.035, 0.04, 0.05, 0.08, 0.09, 10, 15]\n",
        "for c in C:\n",
        "    lr = LogisticRegression(C=c, max_iter=1000, random_state=42)\n",
        "    lr.fit(X_train, y_train)\n",
        "    y_train_pred_lr = lr.predict(X_train)\n",
        "    y_val_pred_lr = lr.predict(X_val)\n",
        "    tr_acc = accuracy_score(y_train, y_train_pred_lr)\n",
        "    val_acc= accuracy_score(y_val, y_val_pred_lr)\n",
        "    print(f\"LR. C = {c}\\ttrain acc: {tr_acc}\\tvalidation acc: {val_acc}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression. C=0.03\tTest ACC: 0.842\n"
          ]
        }
      ],
      "source": [
        "X_final_train = vstack([X_train, X_val])\n",
        "y_final_train = y_train + y_val\n",
        "lr = LogisticRegression(C=15, max_iter=1000)\n",
        "lr.fit(X_final_train, y_final_train)\n",
        "y_test_pred_lr = lr.predict(X_test)\n",
        "test_acc=accuracy_score(y_test, y_test_pred_lr)\n",
        "print(f\"Logistic Regression. C=0.03\\tTest ACC: {test_acc}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Top 30 tokens with highest absolute coefficient values:\n",
            "Token: and                  Coefficient: 6.8889\n",
            "Token: bad                  Coefficient: -5.7792\n",
            "Token: ,                    Coefficient: 4.1227\n",
            "Token: is                   Coefficient: 4.0214\n",
            "Token: plot                 Coefficient: -3.9062\n",
            "Token: ? \n",
            "                  Coefficient: -3.6083\n",
            "Token: as                   Coefficient: 3.4529\n",
            "Token: great                Coefficient: 3.0770\n",
            "Token: worst                Coefficient: -3.0402\n",
            "Token: life                 Coefficient: 2.9402\n",
            "Token: \n",
            "                    Coefficient: -2.8743\n",
            "Token: this                 Coefficient: -2.7662\n",
            "Token: the                  Coefficient: 2.7333\n",
            "Token: *                    Coefficient: -2.7260\n",
            "Token: boring               Coefficient: -2.6989\n",
            "Token: his                  Coefficient: 2.6805\n",
            "Token: to                   Coefficient: -2.6593\n",
            "Token: have                 Coefficient: -2.6422\n",
            "Token: no                   Coefficient: -2.6130\n",
            "Token: , and                Coefficient: 2.6065\n",
            "Token: very                 Coefficient: 2.5363\n",
            "Token: truman               Coefficient: 2.5065\n",
            "Token: nothing              Coefficient: -2.4651\n",
            "Token: stupid               Coefficient: -2.4142\n",
            "Token: n't                  Coefficient: -2.3959\n",
            "Token: well                 Coefficient: 2.3798\n",
            "Token: any                  Coefficient: -2.3168\n",
            "Token: \"                    Coefficient: -2.3089\n",
            "Token: have been            Coefficient: -2.2847\n",
            "Token: script               Coefficient: -2.2778\n",
            "\n",
            "Commentary:\n",
            "The tokens with the highest absolute coefficients are those that the model finds most indicative of a positive or negative review.\n",
            "Often, these tokens include strongly sentiment-laden words or bigrams such as 'excellent', 'terrible', or 'not good'.\n",
            "This makes sense because the model assigns high weights to features that strongly influence its predictions.\n",
            "However, it is not unusual to see a few unexpected tokens; these may arise from n-gram combinations or less obvious contextual indicators.\n",
            "Overall, the list is largely as expected, but reviewing any unexpected tokens can provide insights into potential areas for additional data cleaning or preprocessing.\n"
          ]
        }
      ],
      "source": [
        "feature_names = vectorizer.get_feature_names_out()\n",
        "coefs = lr.coef_.flatten()\n",
        "top30 = np.argsort(np.abs(coefs))[-30:][::-1]\n",
        "print(\"\\nTop 30 tokens with highest absolute coefficient values:\")\n",
        "for idx in top30:\n",
        "    token = feature_names[idx]\n",
        "    coef_value = coefs[idx]\n",
        "    print(f\"Token: {token:20s} Coefficient: {coef_value:.4f}\")\n",
        "\n",
        "print(\"\\nCommentary:\")\n",
        "print(\"The tokens with the highest absolute coefficients are those that the model finds most indicative of a positive or negative review.\")\n",
        "print(\"Often, these tokens include strongly sentiment-laden words or bigrams such as 'excellent', 'terrible', or 'not good'.\")\n",
        "print(\"This makes sense because the model assigns high weights to features that strongly influence its predictions.\")\n",
        "print(\"However, it is not unusual to see a few unexpected tokens; these may arise from n-gram combinations or less obvious contextual indicators.\")\n",
        "print(\"Overall, the list is largely as expected, but reviewing any unexpected tokens can provide insights into potential areas for additional data cleaning or preprocessing.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[377055 213069   5229  71371 474965 298686 409189 308352 454453 465914\n",
            "  19910 305354 212968 444597 221552 100398  19218 423836 438925      2\n",
            " 267026 489227 205644  77332  38227 340904 244499  19574  84650  61239]\n",
            "script\n",
            "have been\n",
            "\"\n",
            "any\n",
            "well\n",
            "n't\n",
            "stupid\n",
            "nothing\n",
            "truman\n",
            "very\n",
            ", and\n",
            "no\n",
            "have\n",
            "to\n",
            "his\n",
            "boring\n",
            "*\n",
            "the\n",
            "this\n",
            "\n",
            "\n",
            "life\n",
            "worst\n",
            "great\n",
            "as\n",
            "? \n",
            "\n",
            "plot\n",
            "is\n",
            ",\n",
            "bad\n",
            "and\n"
          ]
        }
      ],
      "source": [
        "feature_names = vectorizer.get_feature_names_out()\n",
        "coef = lr.coef_.flatten()\n",
        "top_30_tokens =np.argsort(np.abs(coef))[-30:]\n",
        "print(top_30_tokens)\n",
        "for idx in top_30_tokens:\n",
        "    token = feature_names[idx]\n",
        "    print(token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python (myenv)",
      "language": "python",
      "name": "myenv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
